{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FH4Ekc5a_Jq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lung Cancer Prediction\n",
        "\n",
        "\n",
        " Aim : Prediction of Lung Cancer\n",
        "\n",
        "Data source : https://www.kaggle.com/datasets/thedevastator/cancer-patients-and-air-pollution-a-new-link/data\n",
        "\n",
        "\n",
        "### Reason why choosing Lung cancer\n",
        " Lung cancer is the leading cause of cancer death worldwide, accounting for 1.59 million deaths in 2018. The majority of lung cancer cases are attributed to smoking, but exposure to air pollution is also a risk factor. A new study has found that air pollution may be linked to an increased risk of lung cancer, even in nonsmokers.\n",
        "\n",
        "The study, which was published in the journal Nature Medicine, looked at data from over 462,000 people in China who were followed for an average of six years. The participants were divided into two groups: those who lived in areas with high levels of air pollution and those who lived in areas with low levels of air pollution.\n",
        "\n",
        "The researchers found that the people in the high-pollution group were more likely to develop lung cancer than those in the low-pollution group. They also found that the risk was higher in nonsmokers than smokers, and that the risk increased with age.\n",
        "\n",
        "While this study does not prove that air pollution causes lung cancer, it does suggest that there may be a link between the two. More research is needed to confirm these findings and to determine what effect different types and levels of air pollution may have on lung cancer risk\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Descirbe\n",
        "This dataset contains information on patients with lung cancer, including their age, gender, air pollution exposure, alcohol use, dust allergy, occupational hazards, genetic risk, chronic lung disease, balanced diet, obesity, smoking, passive smoker, chest pain, coughing of blood, fatigue, weight loss ,shortness of breath ,wheezing ,swallowing difficulty ,clubbing of finger nails and snoring\n",
        "\n",
        "\n",
        "\n",
        "### Features info\n",
        "\n",
        "Age : The age of the patinet (Numeric)\n",
        "\n",
        "Gender : The gender of the patient (Categorical)\n",
        "\n",
        "Air Pollution : The level of air pollution exposure of the patient (Categorical)\n",
        "\n",
        "Alcohol use : The level of alchol use of the patient (Categorical)\n",
        "\n",
        "Dust Allergy : The levle of dust allergy of patient (Categorical)\n",
        "\n",
        "OccuPational Hazards : The level of occupational hazards of the patient (Categorical)\n",
        "\n",
        "Genetic Risk : The level of genetic risk of the patient (Categorical)\n",
        "\n",
        "Chronic Lung Disease :  The level of chronic lung disease of the patient (Categorical)\n",
        "\n",
        "Balanced Diet : The level of balanced diet of the patient (Categorical)\n",
        "\n",
        "Obesity : The level of obesity of the patient (Categorical)\n",
        "\n",
        "Smoking : The level of smoking of the patient (Categorical)\n",
        "\n",
        "Passive Smoker : The level of passive smoker of the patient (Categorical)\n",
        "\n",
        "Chest Pain : The level of chest pain of the patient (Categorical)\n",
        "\n",
        "Coughing of Blood : The level of coughing of blood of the patient(Categorical)\n",
        "\n",
        "Fatigue : The level of fatigue of the patient (Categorical)\n",
        "\n",
        "Weight Lpss : The level of weight loss of the patient (Categorical)\n",
        "\n",
        "Shortness of Breath : The level of shortness of breath of the patient (Categorical)\n",
        "\n",
        "Wheezing : The level of wheezing of the patient (Categorical)\n",
        "\n",
        "Swallowing Difficulty : The level of swallowing difficulty of the patient (Categorical)\n",
        "\n",
        "Clubbing of Finger Nails : The level of clubbing of finger nail of the patient (Categorical)\n",
        "\n"
      ],
      "metadata": {
        "id": "_JKimivSJ0gj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LskFQXBj-RCo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import kstest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "sns.set()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Load & Checking\n",
        "\n",
        "Flow Chart\n",
        "\n",
        "[Data pre-filtering & Modifying]\n",
        "\n",
        "1. Load data\n",
        "2. Checking sparsity\n",
        "(Do not need to scaling)\n",
        "3. Checking 'Severity' of Lung Cancer\n",
        "4. Remapping Factors to Index [High : 2 , Medium : 1, Low : 0]\n",
        "\n",
        "[Find out influential factors]\n",
        "\n",
        "1. Checking Correlation between features\n",
        "2. Spare corr>0.5\n",
        "\n",
        "[Model modifying]\n",
        "\n",
        "1. Find Best Parameter\n",
        "2. Applying to model\n",
        "3. Cross Validiation(5-fold)\n",
        "\n",
        "[Accuracy Check]\n",
        "\n",
        "1. Confusion Matrix\n",
        "2. ROC Curve\n"
      ],
      "metadata": {
        "id": "hoo4fn7qTgOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('cancer patient data sets (2).csv')\n",
        "df # Patients : 1000 , Features = 26"
      ],
      "metadata": {
        "id": "NBeJ9v4y-T_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "DzPeGJQj-UBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "Bl4MaVTP-UDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Level'].value_counts()"
      ],
      "metadata": {
        "id": "3ui5Lj4K-UFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map = {'High' : 2, 'Medium' : 1, 'Low' : 0}\n",
        "df['Level'].replace(map, inplace = True)\n",
        "df['Level'].unique()"
      ],
      "metadata": {
        "id": "TnJ59uGA-UH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Patient Id', axis = 1)\n",
        "df = df.drop('index', axis = 1)\n",
        "df"
      ],
      "metadata": {
        "id": "7nEcAKRz5fyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Levles distribution\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.pie(df['Level'].value_counts(), labels=df['Level'].value_counts().index,\n",
        "        autopct=lambda p: f'{p:.2f}%\\n{p * sum(df[\"Level\"].value_counts()) / 100:,.0f}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9XNwPrs26TMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=4, nrows=6, figsize=(20, 20))\n",
        "ax = ax.flatten()\n",
        "\n",
        "for i, col in enumerate(df.columns):\n",
        "    sns.violinplot(x=df['Level'].replace(dict(zip(map.values(), map.keys()))),\n",
        "                   y=col, data=df, hue_order='Level', palette='turbo', ax=ax[i])\n",
        "    ax[i].set_title(col.title())\n",
        "\n",
        "plt.tight_layout(pad=0.1, w_pad=0.2, h_pad=2.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dEUDCZ6KB-XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To findout which features are most impactable to Lung Cancer\n",
        "\n",
        "Need to do correlation test between features\n",
        "\n",
        "### [ Correlation method ]\n",
        "\n",
        "1. Pearson\n",
        "2. Spearman\n",
        "3. Kendal\n",
        "\n",
        "Before check correlation\n",
        "\n",
        "!Need to check Normality first by Komogorov-Smirnov"
      ],
      "metadata": {
        "id": "dIGI2p9P8sq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normal distribution Check\n",
        "\n",
        "alpha = 0.05 # Cutoff\n",
        "\n",
        "for features in df.columns:\n",
        "    print(f'{features}')\n",
        "    # K-S\n",
        "    statistic ,pvalue = kstest(df[features], 'norm')\n",
        "\n",
        "    if pvalue > alpha:\n",
        "        print('Non normal distributed')\n",
        "    else:\n",
        "        print('Normal distributed')\n",
        "\n"
      ],
      "metadata": {
        "id": "bwMExBk_-AXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All features is follwing normal distribution\n",
        "\n",
        "Therefore, Okay to use pearson"
      ],
      "metadata": {
        "id": "3cR3oitd_pbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Check between features\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "sns.heatmap(df.corr(), cmap = 'RdYlBu', annot = True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s8eQf3f5-UKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr()[['Level']].sort_values(by = 'Level', ascending = False), annot = True, cmap = 'RdYlBu')"
      ],
      "metadata": {
        "id": "wLHc9s6R-UOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation cutoff 0.5 > corr.score\n",
        "\n",
        "df = df[['Level', 'Coughing of Blood', 'Dust Allergy', 'Passive Smoker', 'OccuPational Hazards', 'Air Pollution', 'chronic Lung Disease', 'Shortness of Breath']]"
      ],
      "metadata": {
        "id": "gEkPw3ziBlic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Data spliting\n",
        "\n",
        "y = df.pop('Level')\n",
        "X = df\n",
        "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = True, random_state = 42)\n",
        "print(f'X_train : {X_train.shape} and X_test : {X_test.shape}')\n",
        "print(f'y_train : {y_train.shape} and y_test : {y_test.shape}')"
      ],
      "metadata": {
        "id": "ZLuTCumE-UQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find best cluster by PCA"
      ],
      "metadata": {
        "id": "5Ax92QlsHHoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2, 7):\n",
        "    pca = PCA(n_components = i)\n",
        "    pca.fit(X_train)\n",
        "    print(f'{i} accuracy : {sum(pca.explained_variance_ratio_ * 100.00) : .2f}%')"
      ],
      "metadata": {
        "id": "seWtoU2jHHNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Factors are three(High, Medium, Low) so we should use multinomial regression model\n",
        "\n",
        "# Finding best parameter\n",
        "param_grid_multi = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'C': [0.1, 1.0, 10.0],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "model = LogisticRegression(multi_class = 'multinomial', max_iter = 3000)\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid_multi, cv = 5, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "id": "en1rKT9c-WB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking Accuracy\n",
        "\n",
        "# Multinomial Classifer\n",
        "\n",
        "classifer_multi = LogisticRegression(multi_class = 'multinomial', C = 0.1, class_weight = 'balanced', penalty = None, solver = 'lbfgs', random_state = 42, max_iter = 3000)\n",
        "\n",
        "classifer_multi.fit(X_train, y_train)\n",
        "\n",
        "predictions_multi = classifer_multi.predict(X_test)\n",
        "\n",
        "\n",
        "print('Multinomial Classifer Test Accuracy', classifer_multi.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "OfB9Ar_D-WEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Validation\n",
        "\n",
        "cv_scores = cross_val_score(classifer_multi, X_train, y_train, cv=5)\n",
        "\n",
        "print('Cross-Validation Scores :', cv_scores)\n",
        "print('Average Cross-Validation Score:', np.mean(cv_scores))"
      ],
      "metadata": {
        "id": "b9LjFgpF-WGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "\n",
        "confusion_mat = confusion_matrix(y_test, predictions_multi)\n",
        "sns.heatmap(confusion_mat, annot = True, fmt = 'd',\n",
        "            cmap = 'RdYlBu',\n",
        "            xticklabels= ['Low', 'Medium', 'High'],\n",
        "            yticklabels = ['Low', 'Medium', 'High'])\n",
        "\n",
        "print(classification_report(y_test, predictions_multi))"
      ],
      "metadata": {
        "id": "JaHYalD4-WIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode labels\n",
        "\n",
        "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2]) # 2 : High, 1 : Medium, 0 : Lows\n",
        "\n",
        "# Calculate ROC curve for each class\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "probs = classifer_multi.predict_proba(X_test)\n",
        "num_classes = 3\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], probs[:, i], drop_intermediate = False)\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binarized.ravel(), probs.ravel(), drop_intermediate = False)\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "# Compute macro-average ROC curve and ROC area\n",
        "\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(num_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "mean_tpr /= num_classes\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot ROC curve\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label=f'micro-average ROC curve (area = {roc_auc[\"micro\"]:0.2f})', color='deeppink', linestyle=':', linewidth=4)\n",
        "plt.plot(fpr[\"macro\"], tpr[\"macro\"], label=f'macro-average ROC curve (area = {roc_auc[\"macro\"]:0.2f})', color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
        "for i, color in zip(range(num_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'ROC curve of class {i} (area = {roc_auc[i]:0.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) for Multi-Class')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xPNSxlQ6-WNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7CkV241-WPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djT1a3iU-WR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZlUevCWq-WUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jU1-zTGr-WWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYQZid7q-WYr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}